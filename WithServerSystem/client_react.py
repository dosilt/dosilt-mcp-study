import asyncio
from mcp import ClientSession
from langchain_mcp_adapters.tools import load_mcp_tools
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
import os
from dotenv import load_dotenv
from mcp.client.sse import sse_client
import uuid
from langchain_core.messages import AIMessage, HumanMessage, ToolMessage

load_dotenv("../.env")


class MCPClient:
    def __init__(self):
        self.model = self.select_model(os.getenv("MODEL_NAME", "gpt-4"))
        self.agent = None
        self.sse_ctx = None
        self.session_ctx = None
        self.is_running = False
        self.thread_id = None

    def select_model(self, model_name):
        """ëª¨ë¸ ì„ íƒ"""
        if "gpt" in model_name or "o1" in model_name:
            model = ChatOpenAI(
                model=model_name,
                api_key=os.getenv("OPENAI_API_KEY"),
                temperature=0.7,
                streaming=True,
                model_kwargs={
                    "parallel_tool_calls": False  # ìˆœì°¨ ì‹¤í–‰
                },
            )
        else:
            model = ChatOpenAI(
                model=model_name,
                base_url=os.getenv("CUSTOM_LLM_URL"),
                api_key="EMPTY",
                temperature=0.7,
                streaming=True,
            )
        return model

    async def start(self, reset_server=True):
        """MCP ì„¸ì…˜ ì‹œì‘"""
        print("ğŸ”Œ ì„œë²„ì— ì—°ê²° ì¤‘...")

        # SSE ì—°ê²°
        self.sse_ctx = sse_client(url="http://localhost:8234/sse")
        read, write = await self.sse_ctx.__aenter__()

        # MCP ì„¸ì…˜
        self.session_ctx = ClientSession(read, write)
        session = await self.session_ctx.__aenter__()

        await session.initialize()

        # Tool ë¡œë“œ
        tools = await load_mcp_tools(session)
        print(f"ğŸ”§ {len(tools)}ê°œ ë„êµ¬ ë¡œë“œë¨")

        # Agent ìƒì„±
        self.agent = create_react_agent(self.model, tools)

        # Thread ID ìƒì„±
        self.thread_id = str(uuid.uuid4())

        self.is_running = True
        print(f"âœ… MCP ì„¸ì…˜ ì‹œì‘! (Thread: {self.thread_id[:8]}...)\n")

        # ì„œë²„ ì´ˆê¸°í™”
        if reset_server:
            await self._reset_server()

    async def _reset_server(self):
        """ì„œë²„ ë°ì´í„° ì´ˆê¸°í™”"""
        print("ğŸ”„ ì„œë²„ ë°ì´í„° ì´ˆê¸°í™” ì¤‘...")
        try:
            config = {"configurable": {"thread_id": self.thread_id}}
            response = await self.agent.ainvoke(
                {"messages": [("user", "clear_all_dataë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”")]}, config=config
            )
            result = response["messages"][-1].content
            print(result)
        except Exception as e:
            print(f"âš ï¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print()

    async def ask_with_streaming(self, message: str) -> str:
        """âœ¨âœ¨ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° + Tool ê°•ì œ ì‚¬ìš©"""
        if not self.is_running:
            return "âŒ ë¨¼ì € start()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!"

        print(f"\n{'=' * 70}")
        print(f"ğŸ’¬ ì§ˆë¬¸: {message}")
        print(f"{'=' * 70}\n")

        # âœ… Tool ì‚¬ìš© ê°•ì œ í”„ë¡¬í”„íŠ¸
        enhanced_message = f"""CRITICAL RULES:
1. You MUST use the available tools for ALL calculations
2. Do NOT calculate anything in your head
3. Do NOT write numbers as results without calling tools
4. Before each tool call, explain your reasoning
5. After each tool result, explain what you learned

Available calculation tools:
- add(a, b): addition
- subtract(a, b): subtraction  
- multiply(a, b): multiplication
- divide(a, b): division
- percentage(value, percent): calculate percentage
- increase_by_percent(value, percent): increase by %
- decrease_by_percent(value, percent): decrease by %
- calculate_average(numbers): average of list
- calculate_sum(numbers): sum of list
- find_max(numbers): maximum value
- find_min(numbers): minimum value
- compare_numbers(a, b): compare two numbers
- is_greater_than(value, threshold): check if greater
- is_less_than(value, threshold): check if less

Task: {message}

Remember: USE TOOLS FOR EVERY CALCULATION! Explain your reasoning before each tool call."""

        config = {"configurable": {"thread_id": self.thread_id}, "recursion_limit": 100}

        thinking_num = 0
        action_num = 0
        current_thinking = ""

        print("ğŸŒŠ Streaming started...\n")

        async for event in self.agent.astream_events(
            {"messages": [("user", enhanced_message)]}, config=config, version="v2"
        ):
            kind = event["event"]

            # ğŸ§  LLM ì‹œì‘
            if kind == "on_chat_model_start":
                thinking_num += 1
                current_thinking = ""
                print(f"{'â”€' * 70}")
                print(f"ğŸ’­ Thought #{thinking_num}:")
                print("   ", end="", flush=True)

            # ğŸŒŠ LLM ìŠ¤íŠ¸ë¦¬ë°
            elif kind == "on_chat_model_stream":
                chunk = event["data"]["chunk"]

                if hasattr(chunk, "content") and chunk.content:
                    print(chunk.content, end="", flush=True)
                    current_thinking += chunk.content

            # âœ… LLM ì¢…ë£Œ
            elif kind == "on_chat_model_end":
                print()  # ê°œí–‰

                if not current_thinking.strip():
                    print("   (No reasoning - function calling mode)")

                output = event["data"].get("output")
                if output and hasattr(output, "tool_calls") and output.tool_calls:
                    print()
                    for tc in output.tool_calls:
                        action_num += 1
                        print(f"ğŸ”§ Action #{action_num}: {tc['name']}")
                        args_str = ", ".join([
                            f"{k}={v}" for k, v in tc["args"].items()
                        ])
                        print(f"   Args: {args_str}")

            # âœ… Tool ì¢…ë£Œ
            elif kind == "on_tool_end":
                tool_output = event["data"].get("output")
                if isinstance(tool_output, list):
                    tool_output = tool_output[0].get("text", str(tool_output))

                print(f"\nğŸ“Š Observation:")
                print(f"   {tool_output}\n")

        print(f"{'=' * 70}")
        print(f"âœ… ì™„ë£Œ! (Thoughts: {thinking_num}, Actions: {action_num})")

        if action_num == 0:
            print(f"\nâš ï¸  ê²½ê³ : Toolì´ í•˜ë‚˜ë„ ì‚¬ìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            print(f"ğŸ’¡  LLMì´ ì§ì ‘ ê³„ì‚°í–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")

        print(f"{'=' * 70}\n")

    async def stop(self):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        if self.session_ctx:
            await self.session_ctx.__aexit__(None, None, None)

        if self.sse_ctx:
            await self.sse_ctx.__aexit__(None, None, None)

        self.is_running = False
        print("ğŸ‘‹ MCP ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")


async def main():
    """ë³µì¡í•œ ê³„ì‚°ìœ¼ë¡œ Tool ì‚¬ìš© ê°•ì œ"""
    client = MCPClient()

    try:
        await client.start(reset_server=True)

        # í…ŒìŠ¤íŠ¸ 1: ë‹¤ë‹¨ê³„ ê³„ì‚°
        print("\n" + "ğŸŸ¢" * 35)
        print("ğŸ§  í…ŒìŠ¤íŠ¸ 1: ë‹¤ë‹¨ê³„ ê³„ì‚° (Tool ê°•ì œ)")
        print("ğŸŸ¢" * 35)
        await client.ask_with_streaming(
            "ë‹¤ìŒì„ ìˆœì„œëŒ€ë¡œ ê³„ì‚°í•´ì¤˜:\n"
            "1. 123 + 456\n"
            "2. ê²°ê³¼ - 78\n"
            "3. ê²°ê³¼ Ã· 12\n"
            "4. ê²°ê³¼ Ã— 25"
        )

        # í…ŒìŠ¤íŠ¸ 2: ë°±ë¶„ìœ¨ ê³„ì‚°
        print("\n" + "ğŸ”µ" * 35)
        print("ğŸ“Š í…ŒìŠ¤íŠ¸ 2: ë°±ë¶„ìœ¨ ê³„ì‚°")
        print("ğŸ”µ" * 35)
        await client.ask_with_streaming(
            "150ì„ 23% ì¦ê°€ì‹œí‚¨ ë‹¤ìŒ, ê·¸ ê²°ê³¼ì—ì„œ 18ì„ ë¹¼ì¤˜"
        )

        # í…ŒìŠ¤íŠ¸ 3: ì—¬ëŸ¬ ê°’ ë¹„êµ
        print("\n" + "ğŸŸ¡" * 35)
        print("âš–ï¸ í…ŒìŠ¤íŠ¸ 3: ì—¬ëŸ¬ ê°’ ë¹„êµ")
        print("ğŸŸ¡" * 35)
        await client.ask_with_streaming(
            "88 Ã— 12, 1500 Ã· 3, 100 Ã— 10ì„ ê°ê° ê³„ì‚°í•˜ê³ ,\n"
            "ê·¸ ì¤‘ ìµœëŒ“ê°’, ìµœì†Ÿê°’, í‰ê· ì„ êµ¬í•´ì¤˜"
        )

        # í…ŒìŠ¤íŠ¸ 4: ê¸°ë¡ ë¶„ì„
        print("\n" + "ğŸŸ£" * 35)
        print("ğŸ“ˆ í…ŒìŠ¤íŠ¸ 4: ê¸°ë¡ ë¶„ì„")
        print("ğŸŸ£" * 35)
        await client.ask_with_streaming(
            "ë‚´ ê³„ì‚° ê¸°ë¡ì„ ë³´ì—¬ì£¼ê³ , í†µê³„ë¥¼ ë¶„ì„í•˜ê³ , ì´í•©ì„ ê³„ì‚°í•´ì¤˜.\n"
            "ì´í•©ì´ 5000ë³´ë‹¤ í¬ë©´ 'ìƒìœ„ê¶Œ', 3000~5000ì´ë©´ 'ì¤‘ìœ„ê¶Œ', ì•„ë‹ˆë©´ 'í•˜ìœ„ê¶Œ'ìœ¼ë¡œ ë¶„ë¥˜í•´ì¤˜"
        )

    finally:
        await client.stop()


async def simple_test():
    """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ - Tool ì‚¬ìš© í™•ì¸"""
    client = MCPClient()

    try:
        await client.start(reset_server=True)

        print("\n" + "ğŸ”µ" * 35)
        print("ğŸ§ª ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸: Tool ì‚¬ìš© í™•ì¸")
        print("ğŸ”µ" * 35)
        await client.ask_with_streaming("10 + 20ì„ ê³„ì‚°í•´ì¤˜")

        print("\n" + "ğŸŸ¢" * 35)
        print("ğŸ§ª ê¸°ë¡ í™•ì¸")
        print("ğŸŸ¢" * 35)
        await client.ask_with_streaming("ë‚´ ê³„ì‚° ê¸°ë¡ì„ ë³´ì—¬ì¤˜")

    finally:
        await client.stop()


if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë¨¼ì €
    # asyncio.run(simple_test())

    # ë˜ëŠ” ì „ì²´ í…ŒìŠ¤íŠ¸
    asyncio.run(main())
