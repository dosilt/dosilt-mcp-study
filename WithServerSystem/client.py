# client.py
import asyncio
from mcp import ClientSession, StdioServerParameters
from langchain_mcp_adapters.tools import load_mcp_tools
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
import os
from dotenv import load_dotenv
from mcp.client.sse import sse_client

load_dotenv("../.env")


class MCPClient:
    def __init__(self, server_script="server.py"):
        self.model = self.select_model(os.getenv("MODEL_NAME"))

        self.server_params = StdioServerParameters(
            command="python",
            args=[server_script],
        )

        self.agent = None
        self.stdio_ctx = None
        self.session_ctx = None
        self.is_running = False

    def select_model(self, model_name):
        if "gpt" in model_name:
            model = ChatOpenAI(
                model=model_name,
                api_key=os.getenv("OPENAI_API_KEY"),
            )

        else:
            model = ChatOpenAI(
                model=model_name,  # vLLMì—ì„œ ë¡œë“œí•œ ëª¨ë¸ëª…
                base_url=os.getenv("CUSTOM_LLM_URL"),  # vLLM ì„œë²„ ì£¼ì†Œ
                api_key="EMPTY",  # vLLMì€ API key ë¶ˆí•„ìš”
                temperature=0.7,
            )

        return model

    async def start(self):
        self.sse_ctx = sse_client(url="http://localhost:8234/sse")
        read, write = await self.sse_ctx.__aenter__()

        self.session_ctx = ClientSession(read, write)
        session = await self.session_ctx.__aenter__()

        await session.initialize()
        tools = await load_mcp_tools(session)
        self.agent = create_react_agent(self.model, tools)

        self.is_running = True
        print("âœ… MCP ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!\n")

    async def ask(self, message: str, show_message=True) -> str:
        """ì—ì´ì „íŠ¸ì—ê²Œ ì§ˆë¬¸"""
        if not self.is_running:
            return "âŒ ë¨¼ì € start()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!"

        if show_message:
            print(f"ğŸ’¬ ì§ˆë¬¸: {message}")

        response = await self.agent.ainvoke({"messages": message})
        result = response["messages"][-1].content

        if show_message:
            print(f"ğŸ¤– ë‹µë³€: {result}\n")

        return result

    async def stop(self):
        if self.session_ctx:
            await self.session_ctx.__aexit__(None, None, None)

        if self.sse_ctx:
            await self.sse_ctx.__aexit__(None, None, None)  # ì œëŒ€ë¡œ ë‹«í˜!

        self.is_running = False
        print("âœ… MCP ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")


async def main():
    """ë©”ì¸ ì‹œë‚˜ë¦¬ì˜¤"""
    client = MCPClient()

    try:
        # ì„¸ì…˜ ì‹œì‘
        await client.start()

        # ì‹œë‚˜ë¦¬ì˜¤ 1: ì´ë¦„ ì„¤ì •
        print("=" * 50)
        print("ğŸ“ ì‹œë‚˜ë¦¬ì˜¤ 1: ì´ë¦„ ì„¤ì •")
        print("=" * 50)
        await client.ask("ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼")

        # # ì‹œë‚˜ë¦¬ì˜¤ 2: ê³„ì‚°í•˜ê¸°
        # print("=" * 50)
        # print("ğŸ§® ì‹œë‚˜ë¦¬ì˜¤ 2: ê³„ì‚°í•˜ê¸°")
        # print("=" * 50)
        # await client.ask("5 + 3ì„ ê³„ì‚°í•´ì¤˜")
        # await client.ask("10 Ã— 2ë¥¼ ê³„ì‚°í•´ì¤˜")
        # await client.ask("20 - 5ë¥¼ ê³„ì‚°í•´ì¤˜")

        # # ì‹œë‚˜ë¦¬ì˜¤ 3: ê¸°ë¡ í™•ì¸
        # print("=" * 50)
        # print("ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ 3: ê¸°ë¡ í™•ì¸")
        # print("=" * 50)
        # await client.ask("ë‚´ ê³„ì‚° ê¸°ë¡ì„ ë³´ì—¬ì¤˜")

        # # ì‹œë‚˜ë¦¬ì˜¤ 4: í†µê³„ í™•ì¸
        # print("=" * 50)
        # print("ğŸ“ˆ ì‹œë‚˜ë¦¬ì˜¤ 4: í†µê³„ í™•ì¸")
        # print("=" * 50)
        # await client.ask("í†µê³„ë¥¼ ë³´ì—¬ì¤˜")

        # # ì‹œë‚˜ë¦¬ì˜¤ 5: ëˆ„ì  í•©ê³„
        # print("=" * 50)
        # print("ğŸ’° ì‹œë‚˜ë¦¬ì˜¤ 5: ëˆ„ì  í•©ê³„")
        # print("=" * 50)
        # await client.ask("ì§€ê¸ˆê¹Œì§€ ê³„ì‚°í•œ ê²°ê³¼ì˜ ì´í•©ì€?")

        # # ì‹œë‚˜ë¦¬ì˜¤ 6: ì´ë¦„ í™•ì¸
        # print("=" * 50)
        # print("ğŸ‘¤ ì‹œë‚˜ë¦¬ì˜¤ 6: ì´ë¦„ í™•ì¸")
        # print("=" * 50)
        # await client.ask("ë‚´ ì´ë¦„ì´ ë­ì•¼?")

    finally:
        # ì„¸ì…˜ ì¢…ë£Œ
        await client.stop()


if __name__ == "__main__":
    asyncio.run(main())
